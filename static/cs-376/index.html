
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>CS 376</title>
    <meta name="description" content="">

    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="shortcut icon" href="../favicon.ico">

    <link rel="stylesheet" type="text/css" href="../assets/css/screen.css?v=b9281c64ce">
    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400">

    <link rel="canonical" href="index.html">
    
    <meta property="og:site_name" content="undeclared">
    <meta property="og:type" content="article">
    <meta property="og:title" content="CS 376">
    <meta property="og:description" content="This is a repository of thoughts and responses from the CS 376 readings: 4/19/14: Cognitive Engineering Models [link] The paper provides a good abstract model of human interaction with a generic interface. The paper fits well its framework...">
    <meta property="og:url" content="http://localhost:2368/cs-376/">
    <meta property="article:published_time" content="2015-04-08T06:35:25.489Z">
    <meta property="article:modified_time" content="2015-04-20T18:38:34.367Z">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="CS 376">
    <meta name="twitter:description" content="This is a repository of thoughts and responses from the CS 376 readings: 4/19/14: Cognitive Engineering Models [link] The paper provides a good abstract model of human interaction with a generic interface. The paper fits well its framework...">
    <meta name="twitter:url" content="http://localhost:2368/cs-376/">
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "undeclared",
    "author": {
        "@type": "Person",
        "name": "Sherman Leung",
        "image": "https://media.licdn.com/mpr/mpr/shrink_200_200/p/5/005/037/286/216e0e4.jpg",
        "url": "http://localhost:2368/author/sherman",
        "sameAs": "http://shermanleung.com"
    },
    "headline": "CS 376",
    "url": "http://localhost:2368/cs-376/",
    "datePublished": "2015-04-08T06:35:25.489Z",
    "dateModified": "2015-04-20T18:38:34.367Z",
    "description": "This is a repository of thoughts and responses from the CS 376 readings: 4/19/14: Cognitive Engineering Models [link] The paper provides a good abstract model of human interaction with a generic interface. The paper fits well its framework..."
}
    </script>

    <meta name="generator" content="Ghost 0.5">
    <link rel="alternate" type="application/rss+xml" title="undeclared" href="../rss/index.html">
</head>
<body class="post-template">

    


<header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        <a class="back-button icon-arrow-left" href="../">Home</a>
        <a class="subscribe-button icon-feed" href="../rss/index.rss">Subscribe</a>
    </nav>
</header>

<main class="content" role="main">

    <article class="post">

        <header class="post-header">
            <h1 class="post-title">CS 376</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2015-04-07">07 April 2015</time> 
            </section>
        </header>

        <section class="post-content">
            <p>This is a repository of thoughts and responses from the CS 376 readings:</p>

<h2 id="41914">4/19/14:</h2>

<p><strong>Cognitive Engineering Models</strong> <a href="http://www2.parc.com/istl/groups/uir/publications/items/UIR-1999-04-Pirolli-Handbook-Cognitive.pdf">[link]</a></p>

<ul>
<li>The paper provides a good abstract model of human interaction with a generic interface. The paper fits well its framework of a psychological study that analyzes and models a human processor. I like how the paper applied traditional psychological analyzes to the "machinery of human cognition" - it definitely read very closely with the way traditional psych literature analyzes human behavior.</li>
<li>If this paper can analyze such tasks with such granuality in the context for humans, how would we compare to computers? I would imagine that computers can perform all of these "tasks" much more effectively and quickly. Does that make computers better workers than us? Is there value in the way humans can adapt to changing scenarios and edge cases that computers may not be able to?</li>
<li>In contrast to the other paper, this paper gives much more depth to its quantifiable measures. I appreciate the framework that the paper uses to describe the interactions humans take with interfaces. In particular, the granuality that the paper takes to build intuition behind a user's uncertainty model took multiple factors that I didn't consider into account ("equally probably alternatives", "information-informatic entropy", etc...).</li>
<li>Pirolli measures task completition quite effectively, but doesn't provide much depth or analysis to more subjective tasks such as identifying what decision to make and how such a decision is engineered from the stimuli of the environment. I would have liked to see less details about GOMS models and more details about the decision tree that laid the foundation for such decisions. The paper acknowledges that as HCI tasks grow more complex, models may become incapable of describing the nuanced ways that stimuli is processed into an action. However, an attempt to address more of these nuanced and subjective behaviors would have been appreciated.  </li>
</ul>

<p><strong>Exploring and Finding Information</strong> <a href="http://hcicourses.stanford.edu/cs376/2014/readings/Exploring_and_Finding_Information.pdf">[link]</a></p>

<ul>
<li>I'm not convinced that shopping websites are the appropriate parallel to make given the author's focus on information + food-foraging parallels. Food as a resource is innately tied with a sense of the community/family a forager feels responsible to and the natural survival instinct; whereas, our shopping interests tend to be more individually tied and scoped within our personal preferences. E-commerce sites are much more with targeting/guiding customers towards specific products rather than the resource-rich wild that engender flight/fight responses. I would've felt like a navigation metaphor - the human ability to wayfind and journey across distant lands - to be a much better metaphor in this sense.</li>
<li>Though the study was limited by the technology of its time, two arguments point to why its findings may not apply to today’s interfaces. Visual elements like tabs, fixed “smart-tracking” navbars (i.e. scrollspy), navigation, etc… Secondly, mobile and web interfaces have been benefitting from the advent of Bayesian classifiers, and personalized big data, that improve the relevance of search results and next steps. That being said, text is still the primary medium through which information is conveyed and the study does provide relevant findings in that way.</li>
<li>Specifically, the study verified that the information sense curve shows the number of relevant documents decreasing at a slower rate as the user continued to find more relevant documents. Findings that suggested that users scan titles, appreciate relevance, and optimize their search for information, were not well quantified in their review. Additionally, there weren’t particularly practical or well-formed action items that the study seemed to suggest that would help designers and developers assist their users in getting the most value out of their interfaces.</li>
<li>I liked how specific the paper outlined the user flow for accomplishing specific tasks. The production rules fit in nicely with the framework that the model took with production memory. I would have appreciated more rigor in the way that the paper described weights and associations between chunks in memory. It would have definitely been interesting to investigate the paper’s discussion of a “spreading activation network” under the lens of a directed graph.</li>
</ul>

<h2 id="41414">4/14/14:</h2>

<p><strong>inFORM</strong> <a href="http://tmg-trackr.media.mit.edu:8020/SuperContainer/RawData/Papers/527-inFORM%20Dynamic%20Physical%20Affordances/Published/PDF">[link]</a></p>

<ul>
<li>This is a fascinating piece of work that almost doubles as an artistic statement. I'm impressed and greatly appreciate the clear efforts of the hardware specialists that made this study possible. I'm also a fan of the technical upper bounds (1.08 N/pin, 0.968 m/s downward speed) that defines a capped, but large space where the researchers could explore interactions. An interface such as this is certainly no small task, and I'm glad the researchers opted to include all the details from back to front that allows readers to really get a clear sense of what they built in addition to why they built it.</li>
<li>The interface designed here combine the tactile, visual, and the actual 3D velocity (speed + direction) that the interface produces itself. This brings the number of variables to at least 7 in comparison to the color + x/y dimensions that we use on our phones. These additional variables contribute to an exponential growth of possible interactions. Forget swiping, pincing, and four-finger swipes, there are boundless unexplored forms of tactile affordances in this interface prompts.</li>
<li>What if we imagine if this interface was more granular? Let's do away with 900 pins and imagine 9,000,000. The applications for such technology in spaces like architecture, structural biology or even game design. Touch screens would turn into touch cubes that add all sorts of dimensionality to complex spaces that struggle with a 2D representation. Even learning physics from an interface would be incredibly insightful.</li>
<li>The one thing that I found this paper lacking in is in the disconnect I felt between the paper's focus on "moving passive objects" and the connections such an interface could make to existing designs through visual means. It's clear that the wow factor of such an interface lies in the motion that it provides to these objects, but I had expected more connection between this work to the current interfaces that exist for now-visual tasks. The paper mentions issues with "jarring" its users with unexpected motion. Instead of trying to make these motions more smooth - why not incorporate the already understood visual affordances that our screens present.</li>
</ul>

<p><strong>Multi-Touch Systems that I Have Known and Loved</strong> <a href="http://www.billbuxton.com/multitouchOverview.html">link</a></p>

<ul>
<li>I enjoyed the historic commentary that Buxton presents. The timeline provides definition to a framework and a context to understand the context of today's touch systems. Understanding where our interfaces come from definitely gives insights into what has worked before and why we've moved in the particular directions that we have. Though sites like <a href="http://localhost:2368/cs-376/pttrns.com">pttn</a> provide great depictions of our visual interfaces, I would love more discussions of our touch interfaces such as the commentary that Buxton provides.</li>
<li>The Bi-Manual input in particular provided an interesting insight into parallelism. I took a brief skim over the paper that Buxton linked to understand how two-handed systems (think gear vs. steering wheels for our cars) can lead to more effective and parallizable interfaces for users. It's definitely understable how much more steep the learning curve is, but I argue that it's this sort of "steepness" that allows the knowledge and skill to stick as a habit. How easy is it to pick up driving again after months of inactivity?</li>
<li>I though the conceptual thought excercise present in Touchlight was really interesting. Though the link doesn't seem to be working, the work alludes to an interactive interface with high potential for extensibility. With multiple degrees of freedom in number of users, gestures, and even the visual representation, I would be really interested in seeing what visual and gesture affordances came out of that study and how we might be able to replicate them in the interfaces we have today.</li>
<li>I was a fan of the way that Buxton broke down all the variables that go into touch interfaces. It really got me thinking about how extensible our current touch interfaces really are. It's not immediately apparent the variables and points of data that our phone screens can synthesize to form a larger and more complex pictures, but Buxton's claim that "there's more to touch-sensing than contact and position" definitely deserves some deeper thought before designing the interfaces that we interact with on our phones.</li>
</ul>

<p><strong>Tangible Bits</strong> <a href="http://web.media.mit.edu/~anjchang/ti01/ishii-chi97-tangbits.pdf">[link]</a></p>

<ul>
<li>This paper relates to a TED talk <a href="https://www.youtube.com/watch?v=QgKCrGvShZs">video</a> that I saw a year ago that hacked Wii remotes to produce cheap, low-cost versions of interactive hardware discussed in this study. It prompts the thought of cost and availability - what if we can make technologies in this study as widespread and cost-effective as the Wii remote? Strip away the stigma we have around the remote in the way we hold and use it, and we have a functional input device with sense of space, direction, and speed. If we take these already functioning input devices and flip the mental model on its head to implement more ubitiquous ways to utilize Wii remotes, I would be interested to see how users respond at scale.</li>
<li>I like that this study makes much more of a concerted effort to emphasize how it fits within the realm of ubitiquous computing. It's clear what ways features of the AmbientROOM "fade into the background" of ubitiquous computing. Though inconsistencies should be noted (e.g. "sounds of rain could be distracting"), the paper makes consistent observations within the realm of ubitiquos computing. The depths that the researchers go to to find appropriate metaphors to bridge the physical and digital worlds are exactly the channels that provide depth to ubitiquos computing.</li>
<li>I wanted to dig deeper on the point that the paper makes on "the ways ambient media can move naturally into the foreground." I find this statement somewhat conflicting to Mark Weiser's affirmation of the "invisible ideal." It's of my opinion that tangible items that prove to be too unfamiliar with the general public's mental models will inevitably cause an unnatural transition from the background to the foreground. Designing ideal bridges between the digital and physical, in my opinion, should keep the information in the passive background and not risk this unnatural transition.</li>
<li>Smart devices nowadays make more and more of an effort to blend into the background while constructing an ever more complex profile of the users they track. Given how widespread and inconspicuous these devices are, aren't they fitting into the paradigm of ubitiquos computing. I argue that these devices pose an effective counterargument to this paper's claim that tangible devices leads to a richer experience of the digital world. Devices don't necessarily need to be grasped or touched to provide a rich and even multisensory experience.</li>
</ul>

<hr>

<h2 id="41214">4/12/14:</h2>

<p><strong>Activity Sensing in the Wild</strong> <a href="https://www.cs.umd.edu/~jonf/publications/Consolvo_ActivitySensingInTheWild-AFieldTrialOfUbiFitGarden_CHI2008.pdf">[link]</a></p>

<ul>
<li>This paper goes a long way to test user interaction in a new frame of mind that I assume the majority of users aren't used to. The paper describes of the commercial products with embedded sensors at the time, and it's clear that the majority of the products were not attempting to bridge the physical and mobile worlds very much at all. Linking all of the phone's infrastructure to the hardware sensors for 12 different prototypes was probably quite time-consuming, but it's clear that the focus of this paper is on the interface and the interactions that  people used to monitor their fitness.</li>
<li>That being said, my main contintion of this paper was the lack of generalizability. I was under the impressiona that the sample size was too small and the responses too subjective to yield much insight into other interfaces particularly those without such sensors. It remains important to the focus of parhaps a product development team at car company, but not for research.</li>
<li>Another contention with this article involved the heavy use of "manually entered activities." This detail makes it hard to accurately gauge the use of the sensors when activities like cycling and other common physical activities such as sports. When the point of this system essentially reduces to a text-based entry, it's hard to understand the major insights that the interface claims for the sensor-focused interactivity.</li>
<li>Within the context of ubiquitous computing, early prototypes of today's wearable devices must have pushed the boundaries of what was possible. It's interesting to see however the main course of these fitness oriented devices turn towards smaller, wearable devices rather than the phone itself. I wonder if today's market would really take to the UbiFit system if it was incorporated into today's smartphone as a standalone device. Would we really react so positively or find it foreign in comparison to the other applications we use our phones for?</li>
</ul>

<p><strong>HydroSense:</strong> <a href="http://www.cs.umd.edu/~jonf/publications/Froehlich_HydroSense-InfrastructureMediatedSinglePointSensingOfWholeHomeWaterActivity_UbiComp2009.pdf">link</a></p>

<ul>
<li>This study provides an interesting, early view of the perception of "smarthomes" that today's Google Nest is pushing towards. The important distinction in this paper, however, is its emphasis in "single-point sensing" whereas the smarthomes of today definitely integrate multiple repository of data collection to form a cohesive story. I liked that the study was able to exhibit such accuracy to the true value of the amount of water used.</li>
<li>Much of the discussion involved analysis of the types of valve detection that felt irrelevant to the true nature of the paper. In my opinion, I thought the novel contribution to the conversation here was the way a user might react to such information of having these accurate measurements of water usage. I would have liked to see much less focus on the analysis of how the flow and the amount of water was calculated and much more discussion on the implications of such sensors and what directions this work could take in terms of integration into the home.</li>
<li>I liked the level of granuality that the paper went into in discussing what the system did not do. The point that the authors made in discussing "partially-open valves" definitely proves relevant to the everyday user (like myself!) Furthermore the discussion of overlapping events arises a common everyday use of the bathroom when several devices are active at one time. This gives a good reflection of what the system is actually able to measure in the typical setting of water usage in a house.</li>
<li>I would have liked to see an additional study that extended upon this work to discover effective ways to present the information that <em>Hydrosense</em> gathers back to the user. Given the Nest interfaces of today, it's clear that an effective smarthome involves a good deal of thought in designing an effective yet elegant interface that literally lives with the user. If we were to take this study one step further and build out ways to actually control water usage remotely - how might that effect our water usage? What implications might that have on our drought?</li>
</ul>

<h2 id="4714designcreation">4/7/14: Design + Creation</h2>

<p><strong>Getting the Right Design and the Design Right</strong> <a href="http://www.billbuxton.com/rightDesign.pdf">[link]</a></p>

<ul>
<li>This paper was an interesting, almost psychological study, on the nature of how diversity of perspective affects the perspective itself. I found the conclusions applicable to needfinding and prototyping research and an argument for a re-evaluation of the design-thinking process which seems to be focused on iterating on a single or main development track of a project. I think that the study was well-done in terms of the scope and the methods that were used to assess the hypothesis. It's nice to see paper prototyping as a vehicle to speed not only product development but to hasten research costs.</li>
<li>I was personally surprised by the contention to the last hypothesis as I initially agreed with the claim that creativity would be more likely in the scenario with multiple designs. I think that the conclusions that the study came to surrounding making suggestions makes sense, though I am skeptical of whether participants simply felt less primed to suggest chances for fear of being 'too unoriginal' as they're surrounded by multiple renditions of a single design. If we imagine the setting of a discussion setting filled with students of different perspectives, I know from personal experience how I feel better equipped to think of discussion points via synthesis and reimagination of what I've already heard. However, despite being better equipped, there is a higher fear of making an "unsignificant" or "unoriginal" remark based on the diversity of opinions around me.</li>
<li>The discussion about choice and decisions reminds me of an interesting point tied to choice paralysis as made popular by Barry Schwartz in "The Paradox of Choice" (and his <a href="http://www.ted.com/talks/barry_schwartz_on_the_paradox_of_choice?language=en">TED talk</a>). I wonder if these findings would hold after extrapolating the experiment to include more choices. I would expect that as the number of choices increases, behavior will be grow to be similar to that of the analysis of a single design. Interestingly enough, design thinking in general seems to push for quantity of ideas over quality - why doesn't this sort of process seem to suffer from choice paralysis?</li>
<li>Though this paper focused mainly on designs for user interfaces, I wonder if findings are relevant and applicable to other forms of design in the frameworks of art, musical composition, or even construction blueprints! What if we have experts or amateurs in the subjects take a similar approach to their design efforts? Would findings indicate a similar trend across the severity and variety of critiques? I would expect differences in subject areas like these to not show significant trends given the complexity of the critiques in these design settings.</li>
</ul>

<p><strong>Webzeitgeist: Design Mining the Web</strong> <a href="http://hci.stanford.edu/publications/2013/Webzeitgeist/webzeitgeist.pdf">[link]</a></p>

<ul>
<li>I appreciate this paper's attention to isolate and focus on a specific research question, that of: "What can we learn from mining design from the web?" The insights here seem well abstracted from the noise of the web given the way that models were defined in terms of position, width, even to the granuality of the number of children elements. The definition of "vision" was particularly interesting, given that it focused on the most common color in the element and particularly paid special attention to edge pixels. Unfortunately, the paper didn't discuss major findings related to these more interesting features of "vision" which I feel is an integral part of design.</li>
<li>The paper made a solid effort in breaking down the components of "design" into quantifiable and easily measurable qualities. However, I wish it explored more complex relations between different visual elements themselves. Specifically, how does the visual interaction between different visual elements on a webpage enhance or detract from the holistic design value of a page? Naive approaches towards this question might include overlap or dx or dy features in relation to the parent or sibling elements, and allowing standard learning algorithms like SARSA to try to predict important features.</li>
<li>I personally enjoyed the amount of technical detail that the paper went into. I can see how others might argue that such attention to technical detail may be superfluous or irrelevant to the exploration of design principles. However, the type of mining that the authors attempted is definitely novel and clearly worthy of extensive discussion alone. In particular, the creation of Design Query Language provided some fascinating insights in how design features can be organized and summarized.</li>
<li>I would have also liked to see an analysis of popular pages - and see if correlation and design mining analysis across popular sites with heavy traffic can lead to the prediction of particular design features that foster "well-designed" features. Of course this venture would require a careful investigation in whether a "popular" site is comprable to a "well-designed" one. However, the investigation raises an interesting inquiry into whether good design conventions correlate with statistically signficant design features according to the design mining techniques presented in this paper.</li>
</ul>
        </section>

        <footer class="post-footer">


            <figure class="author-image">
                <a class="img" href="http://localhost:2368/author/sherman/" style="background-image: url(https://media.licdn.com/mpr/mpr/shrink_200_200/p/5/005/037/286/216e0e4.jpg)"><span class="hidden">Sherman Leung's Picture</span></a>
            </figure>

            <section class="author">
                <h4><a href="http://localhost:2368/author/sherman/">Sherman Leung</a></h4>

                    <p>Student, Teacher, Developer, Designer.</p>
                <div class="author-meta">
                    <span class="author-location icon-location">Stanford, CA</span>
                    <span class="author-link icon-link"><a href="http://shermanleung.com">http://shermanleung.com</a></span>
                </div>
            </section>


            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="https://twitter.com/share?text=CS%20376&amp;url=http://localhost:2368/cs-376/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:2368/cs-376/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=http://localhost:2368/cs-376/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>

        </footer>

    </article>

</main>



    <footer class="site-footer clearfix">
         <section class="copyright"><a href="../">undeclared</a> © 2015</section>
         <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
    </footer>

    <script src="../public/jquery.js?v=b9281c64ce"></script>

    <script type="text/javascript" src="../assets/js/jquery.fitvids.js?v=b9281c64ce"></script>
    <script type="text/javascript" src="../assets/js/index.js?v=b9281c64ce"></script>

</body>
